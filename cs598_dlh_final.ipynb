{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs598_dlh_final",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN_Softmax - CS 598 DLH - Reproducable Paper Final Project\n",
        "\n",
        "This contains the code required for the paper titled \"A Novel Deep Similarity Learning Approach to Electronic Health Records Data\"\n"
      ],
      "metadata": {
        "id": "x4mPcC1aa83O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment setup + Data pre-processing"
      ],
      "metadata": {
        "id": "PTR-kLB4FG0q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1fal44MBuSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a53a8a-fc38-4b27-d04f-e2d3abdc3a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        }
      ],
      "source": [
        "#Environment setup\n",
        "!pip3 install gdown\n",
        "!mkdir data\n",
        "\n",
        "#Imports\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import gdown\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://drive.google.com/uc?id=1uBv9j602LGyN43wvbQDpvka49rR9eNUQ&export=download&confirm=t\n",
        "'''from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1uBv9j602LGyN43wvbQDpvka49rR9eNUQ',\n",
        "                                    dest_path='./data/orbda.csv',\n",
        "                                    unzip=True,\n",
        "                                    showsize=True,\n",
        "                                    overwrite=True)'''\n",
        "\n",
        "\n",
        "url = \"https://drive.google.com/uc?id=1uBv9j602LGyN43wvbQDpvka49rR9eNUQ\"\n",
        "output = \"./data/orbda.csv\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "df = pd.read_csv('data/orbda.csv', low_memory=False) #read in csv file (~800mb)"
      ],
      "metadata": {
        "id": "PlNpKdN1oHJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6532885-87ba-4f75-c411-51656e489506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uBv9j602LGyN43wvbQDpvka49rR9eNUQ\n",
            "To: /content/data/orbda.csv\n",
            "100%|██████████| 818M/818M [00:04<00:00, 190MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sanity checks for pandas import + read_csv\n",
        "#print(df.columns)\n",
        "#print(sorted(df['ap_cidpri'].unique()))\n",
        "#df.head()\n",
        "#print(df['id_'].nunique())\n",
        "#print(df['id_'].count())\n",
        "#print(df['ap_coduni'].unique())\n",
        "#print(df['ap_coduni'].count())"
      ],
      "metadata": {
        "id": "f5hQPH09ET1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iXqUq-5kAVw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering out for specific values as outlined in Table 3\n",
        "kidney_codes = ['E10 ', 'E14 ', 'I10 ', 'I120', 'N039', 'N088', 'N083', 'N180', 'N188', 'N189']\n",
        "df = df.loc[df['ap_cidpri'].isin(kidney_codes)]"
      ],
      "metadata": {
        "id": "4T5yj_6O1XAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering out columns to match input features\n",
        "#Features: an_hcv, an_hiv, an_hbsag, ap_nuidade, ap_coduni, owner_id, ap_pripal, ap_motsai, estado, an_tru, an_intfis, vol\n",
        "column_features = ['an_hcv', 'an_hiv', 'an_hbsag', 'ap_nuidade', 'ap_coduni', 'ap_pripal', 'ap_motsai', 'estado', 'an_tru', 'an_intfis', 'ap_cidpri']\n",
        "df_input_features = df.filter(items=column_features)\n",
        "print(tabulate(df_input_features.head(), headers = 'keys', tablefmt = 'psql'))"
      ],
      "metadata": {
        "id": "oPvj4uyPKBNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c3063e-9ba4-4621-a1bb-65f2efd2b7bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+----------+------------+--------------+------------------+-------------+-------------+----------+----------+-------------+-------------+\n",
            "|    | an_hcv   | an_hiv   | an_hbsag   |   ap_nuidade | ap_coduni        |   ap_pripal |   ap_motsai | estado   |   an_tru |   an_intfis | ap_cidpri   |\n",
            "|----+----------+----------+------------+--------------+------------------+-------------+-------------+----------+----------+-------------+-------------|\n",
            "|  0 | N        | N        | N          |           25 | a1042cb8e9265d4e |   305010107 |          21 | MG       |     628  |          03 | N180        |\n",
            "|  1 | N        | N        | N          |           47 | 69ba059ff91532d3 |   305010107 |          21 | RJ       |     0065 |          00 | N180        |\n",
            "|  2 | N        | N        | N          |           15 | a2b516fa1aa3cce0 |   305010107 |          21 | PR       |     0    |          01 | N180        |\n",
            "|  3 | N        | N        | N          |           37 | 72f15d07e504318f |   305010107 |          21 | RJ       |     6582 |          01 | N180        |\n",
            "|  4 | N        | N        | N          |           71 | 72f15d07e504318f |   305010107 |          21 | RJ       |     7778 |          01 | N180        |\n",
            "+----+----------+----------+------------+--------------+------------------+-------------+-------------+----------+----------+-------------+-------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting ap_coduni values into int via dict\n",
        "coduni_dict = {}\n",
        "unique_coduni = df_input_features['ap_coduni'].unique()\n",
        "for i in range(0, len(unique_coduni)):\n",
        "  coduni_dict[unique_coduni[i]] = i\n",
        "df_input_features = df_input_features.replace({'ap_coduni': coduni_dict})\n",
        "print(tabulate(df_input_features.head(), headers = 'keys', tablefmt = 'psql'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3grtwvAA4CG",
        "outputId": "d30d8189-5af0-4a2c-94f0-1ee2bb968f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------+\n",
            "|    | an_hcv   | an_hiv   | an_hbsag   |   ap_nuidade |   ap_coduni |   ap_pripal |   ap_motsai | estado   |   an_tru |   an_intfis | ap_cidpri   |\n",
            "|----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------|\n",
            "|  0 | N        | N        | N          |           25 |           0 |   305010107 |          21 | MG       |     628  |          03 | N180        |\n",
            "|  1 | N        | N        | N          |           47 |           1 |   305010107 |          21 | RJ       |     0065 |          00 | N180        |\n",
            "|  2 | N        | N        | N          |           15 |           2 |   305010107 |          21 | PR       |     0    |          01 | N180        |\n",
            "|  3 | N        | N        | N          |           37 |           3 |   305010107 |          21 | RJ       |     6582 |          01 | N180        |\n",
            "|  4 | N        | N        | N          |           71 |           3 |   305010107 |          21 | RJ       |     7778 |          01 | N180        |\n",
            "+----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting an_hcv, an_hiv, an_hbsag to int values from dict\n",
        "yes_no_dict = {'N': 0, \"P\": 1}\n",
        "df_input_features = df_input_features.replace({'an_hcv': yes_no_dict, 'an_hiv': yes_no_dict, 'an_hbsag': yes_no_dict})\n",
        "print(tabulate(df_input_features.head(), headers = 'keys', tablefmt = 'psql'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnlKRngRCaka",
        "outputId": "7955ba6b-0b1b-48a3-bbee-b3ca4648d8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------+\n",
            "|    |   an_hcv |   an_hiv |   an_hbsag |   ap_nuidade |   ap_coduni |   ap_pripal |   ap_motsai | estado   |   an_tru |   an_intfis | ap_cidpri   |\n",
            "|----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------|\n",
            "|  0 |        0 |        0 |          0 |           25 |           0 |   305010107 |          21 | MG       |     628  |          03 | N180        |\n",
            "|  1 |        0 |        0 |          0 |           47 |           1 |   305010107 |          21 | RJ       |     0065 |          00 | N180        |\n",
            "|  2 |        0 |        0 |          0 |           15 |           2 |   305010107 |          21 | PR       |     0    |          01 | N180        |\n",
            "|  3 |        0 |        0 |          0 |           37 |           3 |   305010107 |          21 | RJ       |     6582 |          01 | N180        |\n",
            "|  4 |        0 |        0 |          0 |           71 |           3 |   305010107 |          21 | RJ       |     7778 |          01 | N180        |\n",
            "+----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting estado to int values from dict\n",
        "estado_dict = {}\n",
        "unique_estado = df_input_features['estado'].unique()\n",
        "for i in range(0, len(unique_estado)):\n",
        "  estado_dict[unique_estado[i]] = i\n",
        "df_input_features = df_input_features.replace({'estado': estado_dict})\n",
        "print(tabulate(df_input_features.head(), headers = 'keys', tablefmt = 'psql'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1zZ0wVXJG71",
        "outputId": "0e0834cf-958d-40ee-b375-c23abb70d72d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------+\n",
            "|    |   an_hcv |   an_hiv |   an_hbsag |   ap_nuidade |   ap_coduni |   ap_pripal |   ap_motsai |   estado |   an_tru |   an_intfis | ap_cidpri   |\n",
            "|----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------|\n",
            "|  0 |        0 |        0 |          0 |           25 |           0 |   305010107 |          21 |        0 |     628  |          03 | N180        |\n",
            "|  1 |        0 |        0 |          0 |           47 |           1 |   305010107 |          21 |        1 |     0065 |          00 | N180        |\n",
            "|  2 |        0 |        0 |          0 |           15 |           2 |   305010107 |          21 |        2 |     0    |          01 | N180        |\n",
            "|  3 |        0 |        0 |          0 |           37 |           3 |   305010107 |          21 |        1 |     6582 |          01 | N180        |\n",
            "|  4 |        0 |        0 |          0 |           71 |           3 |   305010107 |          21 |        1 |     7778 |          01 | N180        |\n",
            "+----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting an_tru to int values from dict \n",
        "df_input_features['an_tru'] = df_input_features['an_tru'].str.strip()\n",
        "df_input_features['an_tru'] = df_input_features['an_tru'].str.extract('(\\d+)', expand=False)\n"
      ],
      "metadata": {
        "id": "CBLWyefuPMhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting an_intfis to int values from dict \n",
        "\n",
        "intfis_dict = {}\n",
        "unique_intfis = df_input_features['an_intfis'].unique()\n",
        "for i in range(0, len(unique_intfis)):\n",
        "  intfis_dict[unique_intfis[i]] = i\n",
        "df_input_features = df_input_features.replace({'an_intfis': intfis_dict})\n",
        "print(tabulate(df_input_features.head(), headers = 'keys', tablefmt = 'psql'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOKgAGypMdL9",
        "outputId": "616d3035-1e09-4fc2-9426-1af4118b9d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------+\n",
            "|    |   an_hcv |   an_hiv |   an_hbsag |   ap_nuidade |   ap_coduni |   ap_pripal |   ap_motsai |   estado |   an_tru |   an_intfis | ap_cidpri   |\n",
            "|----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------|\n",
            "|  0 |        0 |        0 |          0 |           25 |           0 |   305010107 |          21 |        0 |      628 |           0 | N180        |\n",
            "|  1 |        0 |        0 |          0 |           47 |           1 |   305010107 |          21 |        1 |     0065 |           1 | N180        |\n",
            "|  2 |        0 |        0 |          0 |           15 |           2 |   305010107 |          21 |        2 |        0 |           2 | N180        |\n",
            "|  3 |        0 |        0 |          0 |           37 |           3 |   305010107 |          21 |        1 |     6582 |           2 | N180        |\n",
            "|  4 |        0 |        0 |          0 |           71 |           3 |   305010107 |          21 |        1 |     7778 |           2 | N180        |\n",
            "+----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting pandas object types into integer\n",
        "df_input_features = df_input_features.dropna()\n",
        "df_input_features['an_hcv'] = df_input_features['an_hcv'].astype('str').astype('float')\n",
        "df_input_features['an_hiv'] = df_input_features['an_hiv'].astype('str').astype('float')\n",
        "df_input_features['an_hbsag'] = df_input_features['an_hbsag'].astype('str').astype('float')\n",
        "df_input_features['an_tru'] = df_input_features['an_tru'].astype('str').astype('float')\n",
        "df_input_features['an_intfis'] = df_input_features['an_intfis'].astype('str').astype('float')"
      ],
      "metadata": {
        "id": "ZStaoWUyLjB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sanity checks post filtering\n",
        "#display(df.groupby('ap_cidpri')['ap_cidpri'].transform('count'))\n",
        "print(tabulate(df['ap_cidpri'].value_counts().to_frame(), headers = 'keys', tablefmt = 'psql'))\n",
        "print(tabulate(df_input_features.head(), headers = 'keys', tablefmt = 'psql'))\n",
        "print(df_input_features.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h89LWhmqB5sk",
        "outputId": "793f96d1-026e-49af-ca9c-5526e2b4e8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------+\n",
            "|      |       ap_cidpri |\n",
            "|------+-----------------|\n",
            "| N180 |     3.94376e+06 |\n",
            "| N189 | 38160           |\n",
            "| I120 | 19460           |\n",
            "| N039 |  7349           |\n",
            "| I10  |  5979           |\n",
            "| N083 |  5782           |\n",
            "| N188 |  4670           |\n",
            "| N088 |  1698           |\n",
            "| E10  |   190           |\n",
            "| E14  |   168           |\n",
            "+------+-----------------+\n",
            "+----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------+\n",
            "|    |   an_hcv |   an_hiv |   an_hbsag |   ap_nuidade |   ap_coduni |   ap_pripal |   ap_motsai |   estado |   an_tru |   an_intfis | ap_cidpri   |\n",
            "|----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------|\n",
            "|  0 |        0 |        0 |          0 |           25 |           0 |   305010107 |          21 |        0 |      628 |           0 | N180        |\n",
            "|  1 |        0 |        0 |          0 |           47 |           1 |   305010107 |          21 |        1 |       65 |           1 | N180        |\n",
            "|  2 |        0 |        0 |          0 |           15 |           2 |   305010107 |          21 |        2 |        0 |           2 | N180        |\n",
            "|  3 |        0 |        0 |          0 |           37 |           3 |   305010107 |          21 |        1 |     6582 |           2 | N180        |\n",
            "|  4 |        0 |        0 |          0 |           71 |           3 |   305010107 |          21 |        1 |     7778 |           2 | N180        |\n",
            "+----+----------+----------+------------+--------------+-------------+-------------+-------------+----------+----------+-------------+-------------+\n",
            "an_hcv        float64\n",
            "an_hiv        float64\n",
            "an_hbsag      float64\n",
            "ap_nuidade      int64\n",
            "ap_coduni       int64\n",
            "ap_pripal       int64\n",
            "ap_motsai       int64\n",
            "estado          int64\n",
            "an_tru        float64\n",
            "an_intfis     float64\n",
            "ap_cidpri      object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting categorical lables to one hot encoding\n",
        "kidney_codes_dict = {'E10 ': 1, 'E14 ': 2, 'I10 ': 3, 'I120': 4, 'N039': 4, 'N088': 5, 'N083': 6, 'N180': 7, 'N188': 8, 'N189': 9}\n",
        "\n",
        "cidpri_list = df_input_features['ap_cidpri'].tolist()\n",
        "for i in range(0, len(cidpri_list)):\n",
        "  cidpri_list[i] = kidney_codes_dict[cidpri_list[i]]\n",
        "\n",
        "tensor_cidpri = torch.tensor(cidpri_list)\n",
        "cidpri_one_hot = F.one_hot(tensor_cidpri)\n",
        "\n",
        "#Drop cidpri column since we are now done with it\n",
        "df_input_features = df_input_features.drop(['ap_cidpri'], axis=1)"
      ],
      "metadata": {
        "id": "Vvesj7AoFPhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataloader calss\n",
        "class NephrologyDataset(Dataset):\n",
        "  def __init__(self, input_features, categorical_features):\n",
        "    x = input_features.values\n",
        "    y = categorical_features\n",
        "    print(y)\n",
        "\n",
        "    self.x_train = torch.tensor(x, device=device)\n",
        "    self.y_train = y.to(device)#torch.tensor(y, device=device)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y_train)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return self.x_train[idx], self.y_train[idx]"
      ],
      "metadata": {
        "id": "2vRPoBS8qlzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataloader initialization\n",
        "dataloader = NephrologyDataset(df_input_features[:3190570], cidpri_one_hot[:3190570])\n",
        "train_loader = DataLoader(dataloader,batch_size=10,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YTJRDfGsZIN",
        "outputId": "efd3fd3c-4f81-49c2-e0cb-a45a1e3c6960"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0,  ..., 1, 0, 0],\n",
            "        [0, 0, 0,  ..., 1, 0, 0],\n",
            "        [0, 0, 0,  ..., 1, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 1, 0, 0],\n",
            "        [0, 0, 0,  ..., 1, 0, 0],\n",
            "        [0, 0, 0,  ..., 1, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(cidpri_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xn0zl5a-T3y",
        "outputId": "260bccf6-4817-411d-d280-1a030b223304"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3190573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN_Softmax model definition\n",
        "class CNN_Softmax(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_a = torch.nn.Conv1d(in_channels=10, \n",
        "                                      out_channels=20, \n",
        "                                      kernel_size=1,\n",
        "                                      stride=1)\n",
        "        self.conv_b = torch.nn.Conv1d(in_channels=20, \n",
        "                                      out_channels=10, \n",
        "                                      kernel_size=1,\n",
        "                                      stride=1)\n",
        "        self.maxpool_a = torch.nn.MaxPool1d(kernel_size=1,\n",
        "                                            stride=1)\n",
        "        self.maxpool_b = torch.nn.MaxPool1d(kernel_size=1,\n",
        "                                            stride=1)\n",
        "        self.fc = torch.nn.Linear(in_features=10, \n",
        "                                  out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_a(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.maxpool_a(x)\n",
        "        #print(x.shape)\n",
        "        #print('Finished first conv')\n",
        "        x = self.conv_b(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.maxpool_b(x)\n",
        "        #print(x.shape)\n",
        "        #print('Finished second conv')\n",
        "        x = self.fc(x)\n",
        "        x = F.relu(x)\n",
        "        #print(x.shape)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tsRVyI_vAmzS"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "import torch.optim as optim\n",
        "\n",
        "print(device)\n",
        "net = CNN_Softmax().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "loss_values = []\n",
        "for epoch in tqdm(range(20)):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = []\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.float()\n",
        "        labels = labels.float()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        #print(inputs.shape)\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, \n",
        "                         labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss.append(loss.item())\n",
        "        #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "        #    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "        #    running_loss = 0.0\n",
        "\n",
        "    loss_values.append(np.mean(running_loss))\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "print(loss_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an0st-izLds6",
        "outputId": "e2be8951-b4f5-46b2-ccd3-23baa161b963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [09:54<3:08:11, 594.29s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Graphs + Analysis\n",
        "plt.plot(np.squeeze(loss_values[1:]))"
      ],
      "metadata": {
        "id": "fri1ATDojgdL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}